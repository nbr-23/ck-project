{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiqPabf2jNt4"
      },
      "source": [
        "### Website n° 1 \n",
        "The first website [coincodex.com](https://coincodex.com/crypto/bitcoin/historical-data/) is containing a structured data. It's a basic crypto market website, we can find many others like this one.\n",
        "I am choosing this website as it's containing a historical cryptocurency data.\n",
        "I'll use this data to have a comprehensive market analysis.\n",
        "\n",
        "---\n",
        "# **Why should we scrape the historical data of a cryptocurrency ? ⬇**\n",
        "\n",
        "Because market prices change, both viewers and investors need to keep an eye on the situation. Our web scraping code can keep track of pricing changes and save them in your database for later use. As a result, whenever the prices reach a certain level, you will be able to respond quickly. Select, every coin’s name for extraction. Web scraping tool will find all elements by selecting all the listing names.\n",
        "\n",
        "---\n",
        "\n",
        "### **Why are we using postgres as a database storage ? ⬇**\n",
        "\n",
        "First of all we needed a relational database for our structured data, then i took postgres as it was on the first lines of required skills on your post.\n",
        "\n",
        "PostgreSQL is a powerful, open source object-relational database system that uses and extends the SQL language combined with many features that safely \n",
        "\n",
        "store and scale the most complicated data workloads it's an exellent choise for our use case.\n",
        "\n",
        "\n",
        "### **Why are we using selenium ? ⬇**\n",
        "\n",
        "- It supports Python that i used in this project\n",
        "- It is Open Sourced\n",
        "- It has a multi-browser support\n",
        "- It can be used across various operating systems\n",
        "- It is flexible, easy to test lifecycles\n",
        "- It is having constant updates\n",
        "\n",
        "----\n",
        "\n",
        "Let's start !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fmTGu_8QkrLh"
      },
      "outputs": [],
      "source": [
        "### - Importing dependances - ###\n",
        "\n",
        "from selenium import webdriver\n",
        "options = webdriver.ChromeOptions()\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "options.add_argument('-headless')\n",
        "options.add_argument('-no-sandbox')\n",
        "options.add_argument('-disable-dev-shm-usage')\n",
        "from selenium.webdriver.common.by import By\n",
        "import pandas as pd\n",
        "import regex as re \n",
        "import numpy as np\n",
        "import psycopg2\n",
        "import psycopg2.extras\n",
        "from sqlalchemy import create_engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63pSlINoMmJn"
      },
      "outputs": [],
      "source": [
        "### - Initializing the chromedriver - ###\n",
        "driver = webdriver.Chrome(ChromeDriverManager().install(), options=options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KShmopbPqdJ1"
      },
      "outputs": [],
      "source": [
        "### - Page loading state function - ###\n",
        "\n",
        "def page_is_loading(pDriver):\n",
        "    while True:\n",
        "        x = pDriver.execute_script(\"return document.readyState\")\n",
        "        if x == \"complete\":\n",
        "            return True\n",
        "        else:\n",
        "            yield False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LdXq08OiqZSU"
      },
      "outputs": [],
      "source": [
        "### - Page loading function - ###\n",
        "\n",
        "def load_url(pDriver, pUrl):\n",
        "    is_err = True\n",
        "    while is_err:\n",
        "        try:\n",
        "            pDriver.get(pUrl)\n",
        "            is_err = False\n",
        "        except:\n",
        "            print(' An error occured ')\n",
        "            continue\n",
        "             \n",
        "    while not page_is_loading(pDriver):\n",
        "        continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1RO_juKgJro-"
      },
      "outputs": [],
      "source": [
        "def extract_data(url):\n",
        "\n",
        "  ### - Loading the page - ###\n",
        "\n",
        "  load_url(driver, url)\n",
        "\n",
        "  ### - Retrieving table rows with CSS Selectors form the page - ###\n",
        "  datas = []\n",
        "\n",
        "  nbr_Ligne = len(driver.find_elements(By.CSS_SELECTOR, 'div.section-content > table > tbody > tr')) # The lenth of lines to extract\n",
        "      \n",
        "  # Storing the data in a dictionary\n",
        "\n",
        "  for l in range(nbr_Ligne):\n",
        "      try:\n",
        "          data = dict()\n",
        "              \n",
        "          try:\n",
        "              data['Date'] = driver.find_element(By.CSS_SELECTOR,\"div.section-content > table > tbody > tr:nth-child({}) > td:nth-child(1)\".format(l)).get_attribute(\"innerText\")\n",
        "          except:\n",
        "              data['Date'] = ''\n",
        "          pass\n",
        "\n",
        "          try:\n",
        "              data['Open'] = driver.find_element(By.CSS_SELECTOR,\"div.section-content > table > tbody > tr:nth-child({}) > td:nth-child(2)\".format(l)).get_attribute(\"innerText\")\n",
        "          except:\n",
        "              data['Open'] = ''\n",
        "          pass\n",
        "\n",
        "          try:\n",
        "            data['High'] = driver.find_element(By.CSS_SELECTOR,\"div.section-content > table > tbody > tr:nth-child({}) > td:nth-child(3)\".format(l)).get_attribute(\"innerText\")\n",
        "          except:\n",
        "            data['High'] = ''\n",
        "\n",
        "          try:\n",
        "            data['Low'] = driver.find_element(By.CSS_SELECTOR,\"div.section-content > table > tbody > tr:nth-child({}) > td:nth-child(4)\".format(l)).get_attribute(\"innerText\")\n",
        "          except:\n",
        "            data['Low'] = ''\n",
        "\n",
        "          try:\n",
        "            data['Close'] = driver.find_element(By.CSS_SELECTOR,\"div.section-content > table > tbody > tr:nth-child({}) > td:nth-child(5)\".format(l)).get_attribute(\"innerText\")\n",
        "          except:\n",
        "            data['Close'] = ''\n",
        "\n",
        "          try:\n",
        "            data['Volume'] = driver.find_element(By.CSS_SELECTOR,\"div.section-content > table > tbody > tr:nth-child({}) > td:nth-child(6)\".format(l)).get_attribute(\"innerText\")\n",
        "          except:\n",
        "            data['Volume'] = ''\n",
        "\n",
        "          try:\n",
        "            data['MarketCap'] = driver.find_element(By.CSS_SELECTOR,\"div.section-content > table > tbody > tr:nth-child({}) > td:nth-child(7)\".format(l)).get_attribute(\"innerText\")\n",
        "          except:\n",
        "            data['MarketCap'] = ''\n",
        "\n",
        "          try :\n",
        "            data['Currency'] = driver.find_element(By.XPATH,\"/html/body/app-root/app-breadcrumb/div/div/ul/li[3]/a\").get_attribute(\"innerText\")\n",
        "          except:\n",
        "            data['Currency'] = ''\n",
        "\n",
        "          datas.append(data)\n",
        "\n",
        "      except:\n",
        "              continue\n",
        "\n",
        "  return datas \n",
        "  \n",
        "  driver.close()\n",
        "\n",
        "  ### - | END | - Retrieving table rows with CSS Selectors form the page - ###\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OtSM9Q-XKetU"
      },
      "outputs": [],
      "source": [
        "currencies = ['bitcoin', 'tether'] # we can store those in a file or database \n",
        "\n",
        "### - Creating a link for our scraping - ###\n",
        "\n",
        "def create_link():\n",
        "\n",
        "  with open('structured/urls.csv', 'w') as the_file:\n",
        "      \n",
        "      for currency in currencies:\n",
        "          url = f\"https://coincodex.com/crypto/{currency}/historical-data/ \\n\"\n",
        "          \n",
        "          the_file.write(url)\n",
        "\n",
        "### - | END | - Creating a link for our scraping - ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Q7-Mr2rQUai2"
      },
      "outputs": [],
      "source": [
        "create_link()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "exwDtOc6zIJT"
      },
      "outputs": [],
      "source": [
        "def dataframe(imported_data, crypto_name):\n",
        "\n",
        "  ### - Creatign a DataFrame from loaded data - ###\n",
        "\n",
        "  df_data = pd.DataFrame(imported_data)\n",
        "  df_data = df_data[2:]\n",
        "  df = df_data.reset_index(drop=True)\n",
        "\n",
        "\n",
        "  ### - Cleaning & Preparing data for the storage - ###\n",
        "\n",
        "  # - Replacing commas by  points - #\n",
        "\n",
        "  df_data = df.replace(',','.', regex=True).replace('\\'','', regex=True).replace('\"', '', regex=True)\n",
        "  df_data.head()\n",
        "\n",
        "\n",
        "  # - Remove dollar signs and B(for billion) - #\n",
        "\n",
        "  def remove_chars(s):\n",
        "      return re.sub('[^\\d.,]+', '', s)\n",
        "\n",
        "  df_data['Open'] = df_data['Open'].apply(remove_chars)\n",
        "  df_data['High'] = df_data['High'].apply(remove_chars)\n",
        "  df_data['Low'] = df_data['Low'].apply(remove_chars)\n",
        "  df_data['Close'] = df_data['Close'].apply(remove_chars)\n",
        "  df_data['Volume'] = df_data['Volume'].apply(remove_chars)\n",
        "  df_data['MarketCap'] = df_data['MarketCap'].apply(remove_chars)\n",
        "\n",
        "\n",
        "  # - Converting strings to numbers (float) - #\n",
        "\n",
        "  df_data['Volume'] = pd.to_numeric(df_data['Volume'])\n",
        "  df_data['MarketCap'] = pd.to_numeric(df_data['MarketCap'])\n",
        "  df_data['Open'] = pd.to_numeric(df_data['Open'])\n",
        "  df_data['High'] = pd.to_numeric(df_data['High'])\n",
        "  df_data['Low'] = pd.to_numeric(df_data['Low'])\n",
        "  df_data['Close'] = pd.to_numeric(df_data['Close'])\n",
        "\n",
        "\n",
        "  # - Converting Date column to datetime type - #\n",
        "\n",
        "  df_data['Date'] = df_data['Date'].str.split('.').str.join('').str.split(' ').str.join('-')\n",
        "  df_data['Date'] = df_data['Date'].astype('datetime64[ns]')\n",
        "\n",
        "  # - Converting Volume & Market columns to billions - #\n",
        "\n",
        "  df_data['Volume'] = [x * 1e9 for x in df_data['Volume']]\n",
        "  df_data['MarketCap'] = [x * 1e9 for x in df_data['MarketCap']]\n",
        "\n",
        "\n",
        "  # - Converting large numbers to scientific format - # \n",
        "\n",
        "  df_data['Volume'] = [format(h, \"1.5e\") for h in df_data['Volume']]\n",
        "  df_data['MarketCap'] = [format(h, \"1.5e\") for h in df_data['MarketCap']]\n",
        "\n",
        "  ### - | END | - Cleaning & Preparing data for the storage - ###\n",
        "\n",
        "  # - Saving data to a SCV file - #\n",
        "  \n",
        "  df_data.to_csv(\"structured/historical_data\" + crypto_name +\".csv\", index=False)\n",
        "\n",
        "  return df_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "o_FSNdVrOjyq"
      },
      "outputs": [],
      "source": [
        "### - Calling function to create our links - ###\n",
        "\n",
        "create_link()\n",
        "\n",
        "### - Calling our scraping function with the list of extracted links - ###\n",
        "\n",
        "with open('structured/urls.csv') as f:\n",
        "  lines = f.readlines()\n",
        "\n",
        "for url in lines:\n",
        "\n",
        "    extracted_data = extract_data(url) # Extracting data\n",
        "\n",
        "    currency_name = extracted_data[1]['Currency']\n",
        "\n",
        "    with open( 'structured/' + currency_name  +'.csv', 'w') as the_file: # Writing data in a CSV file ( raw data )\n",
        "\n",
        "      the_file.write(str(extracted_data))\n",
        "\n",
        "      data = dataframe(extracted_data, currency_name) # Cleaning & Creating a DataFrame & saving in a CSV file\n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Preparing and storing data in the database :\n",
        "\n",
        "# Extracting data to store in a database\n",
        "df = pd.read_csv(\"historical_data Tether.csv\", index_col=0)\n",
        "\n",
        "engine = create_engine('\"postgresql://postgres:0258@localhost/historical_data\"')\n",
        "\n",
        "# Updating crypto\n",
        "df_currency = engine.execute(\"SELECT id, name as Currency FROM public.crypto\").fetchall() # Selecting the sql query\n",
        "df_data_currency = pd.DataFrame(df.groupby([\"Currency\"]).count(), columns=[\"Currency\"])\n",
        "df_data_currency[\"Currency\"] = df_data_currency.index\n",
        "df_data_currency.reset_index(drop=True, inplace=True)\n",
        "\n",
        "for i in df_currency : \n",
        "    df_data_currency = df_data_currency[df_data_currency['Currency'] != str(i[1])]\n",
        "df_data_currency = df_data_currency.rename(columns={'Currency': 'name'}) # Undating the name to insert to the database\n",
        "df_data_currency.to_sql('crypto', engine,if_exists='append', index=False) # Inserting the data\n",
        "\n",
        "# Updating historical_data \n",
        "df_currency = engine.execute(\"SELECT id, name as Currency FROM public.crypto\").fetchall() # Selecting existing crypto\n",
        "df_currency = pd.DataFrame(df_currency, columns=[\"id\", \"Currency\"])\n",
        "df_res = df.join(df_currency.set_index(\"Currency\"), lsuffix='_data', on=\"Currency\", how=\"inner\")\n",
        "df_res = df_res.drop(columns={'Currency'}).rename(columns={'id' : 'currency'})\n",
        "df_res.to_sql('historical_data', engine,if_exists='append') # Inserting the data in the  historical_data table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "scraping_file.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
